{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### going to run the code line by line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"#eval\" refers to evaluating tf code and translating the output to a numpy file through the function tf_eval\n",
    "\n",
    "\"#checkpoint\" refers to converting a np array evaulated through tf_eval into a tf tensor and use it in the code. This way the code will not run from the very beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist let's create y_map for two images, one with boats and on without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margheritarosnati/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/margheritarosnati/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import image as mpimg\n",
    "import random\n",
    "#import pyplot as pl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_eval(tf_tensor,timed=0):\n",
    "    if timed:\n",
    "        startTime = time.time()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        np_output = tf_tensor.eval(session=sess)\n",
    "    if timed:\n",
    "        print(\"time:\",time.time()-startTime)\n",
    "    return np_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to create training files\n",
    "def read_images(filenames):\n",
    "    '''\n",
    "    Function applied to every data entry to load the data. The output of this is the input format\n",
    "    to the model.\n",
    "    :param filename: filename\n",
    "    :param y_map: y_data (passes straight through)\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    imgs = []\n",
    "    for i in range(len(filenames)):\n",
    "        print(filenames[i])\n",
    "        imgs.append(mpimg.imread(filenames[i]))\n",
    "    imgs = np.asarray(imgs)\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def get_y_data(filename):\n",
    "    '''\n",
    "    Converts a filename into an array, with one channel for each boat in the image\n",
    "    :param filename: filename string\n",
    "    :return: np array of size [h, w, n_boats_in_this_image]\n",
    "    '''\n",
    "\n",
    "    ground_truths = y_raw[y_raw.ImageId == filename]\n",
    "    array_of_coords = np.array(ground_truths[['lt_x', 'lt_y', 'rb_x', 'rb_y']])\n",
    "    # array_of_coords is of shape [n_boxes, 4]\n",
    "\n",
    "    n_boxes = array_of_coords.shape[0]\n",
    "    y_map = np.zeros((768, 768, n_boxes))\n",
    "    y_reg = np.zeros((768, 768, n_boxes, 4))\n",
    "\n",
    "    for box_idx in range(n_boxes):\n",
    "        # Loop over amount of boats per image ~ of order 10.\n",
    "        box = array_of_coords[box_idx, :]\n",
    "        y_map[box[0]:box[2], box[1]:box[3], box_idx] = 1\n",
    "\n",
    "        # Add boat box coordinates to y_reg\n",
    "        y_reg[:, :, box_idx, 0] = round((box[2] + box[0]) / 2)  # x-centre\n",
    "        y_reg[:, :, box_idx, 1] = round((box[3] + box[1]) / 2)  # y-centre\n",
    "        y_reg[:, :, box_idx, 2] = box[2] - box[0]  # width\n",
    "        y_reg[:, :, box_idx, 3] = box[3] - box[1]  # height\n",
    "\n",
    "    return y_map, y_reg\n",
    "\n",
    "def padder(list_of_arr):\n",
    "    '''\n",
    "    Pads each list of boat maps so all have the same depth (which is the max amount of\n",
    "    boats across all images) and creates a numpy array of the result.\n",
    "    :param list_of_arr: list of arrays, each shaped [768, 768, n_boats_in_this_image]\n",
    "    :return: numpy array of shape [len(list_of_arr), h, w, maximum_n_boats]\n",
    "    '''\n",
    "\n",
    "    maximum_n_boats = max([x.shape[2] for x in list_of_arr])\n",
    "    dim_arr = list_of_arr[0].shape\n",
    "\n",
    "    n_box_max = maximum_n_boats\n",
    "\n",
    "    b = np.zeros([len(list_of_arr), dim_arr[0], dim_arr[1], maximum_n_boats])\n",
    "    for i, arr in enumerate(list_of_arr):\n",
    "        b[i,:, :, :arr.shape[2]] = arr\n",
    "    return b\n",
    "\n",
    "def padder_coord(list_of_arr):\n",
    "    '''\n",
    "    Pads each list of boat maps so all have the same depth (which is the max amount of\n",
    "    boats across all images) and creates a numpy array of the result.\n",
    "    :param list_of_arr: list of arrays, each shaped [768, 768, n_boats_in_this_image, depth] (depth typically 4)\n",
    "    :return: numpy array of shape [len(list_of_arr), h, w, maximum_n_boats, depth]\n",
    "    '''\n",
    "\n",
    "    maximum_n_boats = max([x.shape[2] for x in list_of_arr])\n",
    "    dim_arr = list_of_arr[0].shape\n",
    "    depth = dim_arr[-1]\n",
    "\n",
    "    b = np.zeros([len(list_of_arr), dim_arr[0], dim_arr[1], maximum_n_boats, depth])\n",
    "    for i, arr in enumerate(list_of_arr):\n",
    "        b[i, :, :, :arr.shape[2], :] = arr\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_file =  \"../data/labels/boxes_v2.csv\"\n",
    "y_raw = pd.read_csv(labels_file)\n",
    "\n",
    "sub_input = ['0a148697c.jpg' , '0a0aeea56.jpg']\n",
    "training_data_path = \"../data/train_sample/\"\n",
    "filenames = [training_data_path + x for x in sub_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont run me twice\n",
    "input_img = read_images(filenames)\n",
    "\n",
    "y_data = []\n",
    "y_reg = []\n",
    "for file in sub_input:\n",
    "    out_y_data = get_y_data(file)\n",
    "    y_data.append(out_y_data[0])\n",
    "    y_reg.append(out_y_data[1])\n",
    "\n",
    "y_data = padder(y_data)\n",
    "y_reg = padder_coord(y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dont run me twice\n",
    "# let's save these files so that we wont have to do this again\n",
    "y_data_path = \"debug/y_data.pkl\"\n",
    "y_reg_path = \"debug/y_reg.pkl\"\n",
    "np.save(y_data_path, y_data)\n",
    "np.save(y_reg_path, y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train_sample/0a148697c.jpg\n",
      "../data/train_sample/0a0aeea56.jpg\n"
     ]
    }
   ],
   "source": [
    "# run me from time 2\n",
    "y_data_path = \"debug/y_data.pkl\"\n",
    "y_reg_path = \"debug/y_reg.pkl\"\n",
    "y_data = np.load(y_data_path+\".npy\")\n",
    "y_reg = np.load(y_reg_path+\".npy\")\n",
    "\n",
    "sub_input = ['0a148697c.jpg' , '0a0aeea56.jpg']\n",
    "training_data_path = \"../data/train_sample/\"\n",
    "filenames = [training_data_path + x for x in sub_input]\n",
    "input_img = read_images(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768, 768, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's run the code \"line by line\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.convert_to_tensor(input_img, tf.float32)\n",
    "y_map = tf.convert_to_tensor(y_data, tf.float32)\n",
    "y_reg = tf.convert_to_tensor(y_reg, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(768), Dimension(768), Dimension(3)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand_anchor_shapes_for_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First let's try 2 anchors\n",
    "anchor_shapes = [(21,21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#anchor_shapes = [(21,21), (21, 41), (41,21), (41, 81), (81, 41), (51,51), (151,81), (81, 151), (101,101), (201,201)]\n",
    "n_anchors = len(anchor_shapes)\n",
    "y_anchors = np.zeros((1, 768, 768, n_anchors, 4))\n",
    "x = np.arange(768)\n",
    "X, Y = np.meshgrid(x, x)\n",
    "y_anchors[:, :, :, :, 0] = np.reshape(Y, (1, 768, 768, 1))\n",
    "y_anchors[:, :, :, :, 1] = np.reshape(X, (1, 768, 768, 1))\n",
    "i = 0\n",
    "for anchor_shape in anchor_shapes:\n",
    "    y_anchors[:, :, :, i, 2] = np.ones((1, 768, 768)) * anchor_shape[0]  # width\n",
    "    y_anchors[:, :, :, i, 3] = np.ones((1, 768, 768)) * anchor_shape[1]  # length\n",
    "    i += 1\n",
    "# this last part needs to stay here with this code construction: we change the first dimension of\n",
    "# the reg_anchors to the batch size implicitly (unsure if it works if done explicitly)\n",
    "reg_anchors = tf.tile(y_anchors, multiples=[tf.shape(y_reg)[0], 1, 1, 1, 1])\n",
    "reg_anchors = tf.cast(reg_anchors, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "np_reg_anchors = tf_eval(reg_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_reg_anchors generates a matrix that has for every image and every anchor, \n",
    "# the centre, height and width of the anchor for each pxel\n",
    "print(np_reg_anchors.shape)\n",
    "print(np_reg_anchors[0,0,0,0,:]) # anchor shape is (21,21) centered at (0,0)\n",
    "print(np_reg_anchors[0,5,10,0,:]) # anchor shape is (21,21) centered at (5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is where we unwrap the y masks to be IOU maps and then maps that match the loss.\n",
    "y_class = []\n",
    "selected_boat_index = []\n",
    "iou_mask = []\n",
    "iou_average_for_summary = []\n",
    "pos_mask = []\n",
    "neg_mask = []\n",
    "n_box = tf.shape(y_map)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: the code below iterates per anchor shape. We'll first run it on the first shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "anchor shape = (21,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ NOTE: dont run me twice unless absolutely necessary!!\n",
    "# Loop over number of anchors ~ of order 9\n",
    "# The y_map is of shape [batch_size, h, w, max_n_boats]\n",
    "# The kenerl we convolve with is of shape [anchor_shape[0], anchor_shape[1], max_n_boats, max_n_boats]\n",
    "# where every entry is 0 except for [:,:, i, i] for all i.\n",
    "# (I think) this is equivalent to running a seperate \"all ones\" [anchor_shape[0], anchor_shape[1], 1]\n",
    "# kernel over each of the max_n_boats inputs.\n",
    "# TODO: double (triple, quadruple...) check above logic.\n",
    "\n",
    "anchor = tf.zeros((anchor_shape[0], anchor_shape[1], n_box, n_box))\n",
    "diagonal = tf.ones((anchor_shape[0], anchor_shape[1], n_box))\n",
    "anchor_area = anchor_shape[0]*anchor_shape[1]\n",
    "\n",
    "# Assigns ones to anchor[:,:,i,i] (https://www.tensorflow.org/api_docs/python/tf/linalg/set_diag)\n",
    "anchor = tf.linalg.set_diag(anchor, diagonal)\n",
    "\n",
    "# Calculates the intersection of anchor with each gt map in y_map simulatenously (as above)\n",
    "intersection = tf.nn.conv2d(y_map, anchor, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# union is the area of the map (per map layer, and per batch entry) + the anchor area (in 2d)\n",
    "# TODO: check that minusing intersection does so entry wise.\n",
    "union = tf.reduce_sum(y_map, [1, 2], keepdims=True) + anchor_area - intersection\n",
    "old_ious = tf.divide(intersection, union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ NOTE: dont run me twice unless absolutely necessary!!\n",
    "# evaluate\n",
    "np_ious = tf_eval(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ NOTE: dont run me twice unless absolutely necessary!!\n",
    "# IOUs take some time to evaluate so we are going to save the instance and run TF from here\n",
    "ious_path = \"debug/ious.pkl\"\n",
    "np.save(ious_path, np_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ NOTE: take me instead of running twice the guy above\n",
    "ious_path = \"debug/ious.pkl\"\n",
    "np_ious = np.load(ious_path+\".npy\")\n",
    "ious = tf.convert_to_tensor(np_ious, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np_ious.shape) # (2, 768, 768, 6) where 6 is the number of boats\n",
    "print(np.sum(np_ious[1,:])) # this should be zero and it is\n",
    "for i in range(6):\n",
    "    print(\"sum:\",np.sum(np_ious[0,:,:,i]), \"\\tmax\", np.amax(np_ious[0,:,:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "ious = tf.convert_to_tensor(np_ious, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iou_positive_threshold = 0.5\n",
    "iou_negative_threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iou_over_ground_truth = tf.reduce_max(ious, -1)\n",
    "# for the regression ,we need to know which boat we want to look at\n",
    "argmax_iou_over_ground_truth = tf.argmax(ious, -1)\n",
    "\n",
    "iou_average_for_summary.append(max_iou_over_ground_truth)\n",
    "\n",
    "labels = tf.greater(max_iou_over_ground_truth, iou_positive_threshold)\n",
    "labels = tf.cast(labels, tf.float32)\n",
    "\n",
    "# We only deal in both losses with boxes with IOU above a upper threshold and\n",
    "# below a lower threshold and so here we create a mask which will be 1 for\n",
    "# all such iou scores and 0 for those inside the threshold so we can\n",
    "# use it as a weighting for the losses\n",
    "pos_labels = tf.cast(tf.greater(max_iou_over_ground_truth,\n",
    "                                iou_positive_threshold), tf.float32)\n",
    "neg_labels = tf.cast(tf.less(max_iou_over_ground_truth,\n",
    "                             iou_negative_threshold), tf.float32)\n",
    "\n",
    "\n",
    "pos_mask.append(pos_labels)\n",
    "neg_mask.append(neg_labels)\n",
    "\n",
    "#iou_mask_anchor = pos_labels + neg_labels\n",
    "# iou_mask shape: [batch, 768, 768, n_proposal_boxes]\n",
    "#iou_mask.append(tf.cast(iou_mask_anchor, tf.float32))\n",
    "\n",
    "y_class.append(labels)\n",
    "selected_boat_index.append(argmax_iou_over_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack all the anchors together in the end this is then of shape [batch, 768, 768, n_anchor]\n",
    "y_class = tf.stack(y_class, axis=-1)\n",
    "selected_boat_index = tf.stack(selected_boat_index, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "np_y_class = tf_eval(y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np_y_class.shape) # (2, 768, 768, 1) where 1 is the number of anchors\n",
    "print(np.sum(np_y_class[1,:])) # this should be zero and it is\n",
    "print(\"sum:\",np.sum(np_y_class[0,:,:,0]), \"\\tmax\", np.amax(np_y_class[0,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack IOU masks\n",
    "temp_pos_mask = tf.stack(pos_mask, -1)\n",
    "temp_neg_mask = tf.stack(neg_mask, -1)\n",
    "#iou_mask = tf.stack(iou_mask, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "np_temp_pos_mask = tf_eval(temp_pos_mask)\n",
    "np_temp_neg_mask = tf_eval(temp_neg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(\"\\n\\nImage \",i)\n",
    "    print(\"Fist check: are there any NaNs:\",np.sum(np.isnan(np_temp_pos_mask[i])), np.sum(np.isnan(np_temp_neg_mask[i])))\n",
    "    print('perc. positives:',np.sum(np_temp_pos_mask[i])/(768**2), \"\\tnum positives\",np.sum(np_temp_pos_mask[i]))\n",
    "    print('perc. negatives:',np.sum(np_temp_neg_mask[i])/(768**2), \"\\tnum negatives\",np.sum(np_temp_neg_mask[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IOUs take some time to evaluate so we are going to save the instance and run TF from here\n",
    "path = \"debug/np_temp_pos_mask.pkl\"\n",
    "np.save(path, np_temp_pos_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "y_class = tf.convert_to_tensor(np_y_class, tf.float32)\n",
    "temp_pos_mask = tf.convert_to_tensor(np_temp_pos_mask, tf.float32)\n",
    "temp_neg_mask = tf.convert_to_tensor(np_temp_neg_mask, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter_groundtruth_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_with_matrix_tf(tensor, indexer, batch_size):\n",
    "    '''\n",
    "    :param tensor: input tensor of shape [batch, h, w, depth, n_vals]\n",
    "    :param indexer: indexing tensor of shape [batch, h, w] of ints which\n",
    "    indicates which layer of the depth dimension to take\n",
    "    :param batch_size: neccesary since first dim of tensor maybe none and cant set range(None) tensor\n",
    "    :return: tensor of shape [batch, h, w, n_vals]\n",
    "    '''\n",
    "    batch_size_adaptive, h, w, depth, n_vals = tensor.get_shape().as_list()\n",
    "    desired_shape = [batch_size, h, w]\n",
    "    index_list = [\n",
    "        tf.broadcast_to(tf.reshape(tf.range(batch_size, dtype=tf.int64), (-1, 1, 1)), desired_shape),\n",
    "        tf.broadcast_to(tf.reshape(tf.range(h, dtype=tf.int64), (1, -1, 1)), desired_shape),\n",
    "        tf.broadcast_to(tf.reshape(tf.range(w, dtype=tf.int64), (1, 1, -1)), desired_shape),\n",
    "        indexer\n",
    "    ]\n",
    "    index = tf.stack(index_list, -1)\n",
    "    return tf.gather_nd(tensor, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter y_reg by which boxes are positive\n",
    "y_reg_gt = []\n",
    "k=0\n",
    "# For each anchor run select_with_matrix_tf which filters the map of regression\n",
    "# coordinates y_reg to the (per pixel) particular boat indicated by selected_boat_index\n",
    "y_reg_gt_anchor = select_with_matrix_tf(tensor=y_reg,\n",
    "                                        indexer=selected_boat_index[:,:,:, k],\n",
    "                                        batch_size=2)\n",
    "y_reg_gt.append(y_reg_gt_anchor)\n",
    "\n",
    "y_reg_gt = tf.stack(y_reg_gt, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "np_y_reg_gt = tf_eval(y_reg_gt,timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np_y_reg_gt.shape, np.sum(np.isnan(np_y_reg_gt)))\n",
    "# we only care for this function for the boat matrix\n",
    "np.sum(np_y_reg_gt[0,:]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "y_reg_gt = tf.convert_to_tensor(np_y_reg_gt, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_positive_samples = 100\n",
    "n_negative_samples = 50\n",
    "n_negative_samples_when_no_boats = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_sample(labels, label=1, n_samples=180):\n",
    "    mask = np.zeros(labels.shape, dtype = float)\n",
    "    # if we have np.sum(labels) = 0 we should have n_sample=0 as well\n",
    "    #if n_samples > 0 & np.sum(labels) > 0:\n",
    "    if n_samples > 0:\n",
    "        idx1 = np.where(labels == label)\n",
    "        idx1 = np.asarray(idx1)\n",
    "        index = np.random.randint(idx1.shape[1], size=(n_samples))\n",
    "        a = idx1[:, index]\n",
    "        mask[a[0], a[1], a[2]] = label\n",
    "        mask.astype(float)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counting the number of positive samples.\n",
    "# if there are zero, then  we are in a \"no_boats\" batch image and sample consequently\n",
    "# note: instead of tf.reduce_sum(self.y_map) > 0, we want tf.reduce_sum(self.y_map, [1,2,3])\n",
    "# the latter gives us the sum of the ground truth per image\n",
    "# if the sum is positive, then there are boats in the image and we want to sample some\n",
    "# TODO: fix :)\n",
    "class_mask = []\n",
    "pos_mask = []\n",
    "for i in range(2):\n",
    "    sliced_temp_pos_mask = tf.slice(temp_pos_mask,begin=[i,0,0,0],size=[1,-1,-1,-1])\n",
    "    summed_pos_mask = tf.reduce_sum(sliced_temp_pos_mask)\n",
    "    n_positive_samples = tf.cond(summed_pos_mask > 0,\n",
    "                             lambda: n_positive_samples,\n",
    "                             lambda: 0)\n",
    "    n_negative_samples = tf.cond(summed_pos_mask > 0,\n",
    "                             lambda: n_negative_samples,\n",
    "                             lambda: n_negative_samples_when_no_boats)\n",
    "\n",
    "    # sampling\n",
    "    # note that atm pos_sample applies the same sampling over the whole batch\n",
    "    # refer to utils for the function\n",
    "    # TODO: fix :)\n",
    "    pos_sample = tf.py_func(np_sample, [temp_pos_mask[i], 1, n_positive_samples], tf.float64)\n",
    "    pos_sample = tf.cast(pos_sample, tf.float32)\n",
    "    #pos_mask = temp_pos_mask * pos_sample\n",
    "    neg_sample = tf.py_func(np_sample, [temp_neg_mask[i], 1, n_negative_samples], tf.float64)\n",
    "    neg_sample = tf.cast(neg_sample, tf.float32)\n",
    "    #neg_mask = temp_neg_mask * neg_sample\n",
    "\n",
    "    temp_class_mask = pos_sample + neg_sample\n",
    "    class_mask.append(temp_class_mask)\n",
    "    pos_mask.append(pos_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.087090253829956\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "np_summed_pos_mask = tf_eval(summed_pos_mask,timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.5622100830078125\n"
     ]
    }
   ],
   "source": [
    "np_n_positive_samples = tf_eval(n_positive_samples,timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.1749320030212402\n"
     ]
    }
   ],
   "source": [
    "np_pos_sample = tf_eval(pos_sample,timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1) 0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(np_pos_sample.shape, np.sum(np.isnan(np_pos_sample)), np.sum(np_pos_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_mask = tf.stack(class_mask, 0)\n",
    "pos_mask = tf.stack(pos_mask, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.2557168006896973\n",
      "time: 1.487652063369751\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "np_class_mask = tf_eval(class_mask, timed=1)\n",
    "np_pos_mask = tf_eval(pos_mask, timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(np_class_mask)), np.sum(np.isnan(np_pos_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "def create_convolutional_layer(input,\n",
    "                               num_input_channels,\n",
    "                               conv_filter_size,\n",
    "                               num_filters,\n",
    "                               maxpool=1,\n",
    "                               name=None):\n",
    "    with tf.name_scope(name):\n",
    "        ## We shall define the weights that will be trained using create_weights function.\n",
    "        weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "        ## We create biases using the create_biases function. These are also trained.\n",
    "        biases = create_biases(num_filters)\n",
    "\n",
    "        ## Creating the convolutional layer\n",
    "        layer = tf.nn.conv2d(input=input,\n",
    "                             filter=weights,\n",
    "                             strides=[1, 1, 1, 1],\n",
    "                             padding='SAME')\n",
    "\n",
    "        layer += biases\n",
    "\n",
    "        ## We shall be using max-pooling.\n",
    "        if maxpool == 1:\n",
    "            layer = tf.nn.max_pool(value=layer,\n",
    "                                   ksize=[1, 2, 2, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   padding='SAME')\n",
    "        ## Output of pooling is fed to Relu which is the activation function for us.\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "        return layer\n",
    "    \n",
    "def create_deconvolutional_layer(input, num_filters, name, upscale_factor):\n",
    "    kernel_size = 2 * upscale_factor - upscale_factor % 2\n",
    "    stride = upscale_factor\n",
    "    strides = [1, stride, stride, 1]\n",
    "    with tf.name_scope(name):\n",
    "        # Shape of the input tensor\n",
    "        batch_size = tf.shape(input)[0]\n",
    "        input_size = input.get_shape().as_list()[1]\n",
    "        h = input_size * stride\n",
    "        w = input_size * stride\n",
    "        # put everything together\n",
    "        ds = [batch_size]\n",
    "        ds.append(h)\n",
    "        ds.append(w)\n",
    "        ds.append(num_filters)\n",
    "        deconv_shape = tf.stack(ds)\n",
    "\n",
    "        filter_shape = [kernel_size, kernel_size, num_filters, num_filters]\n",
    "        weights = get_bilinear_filter(filter_shape, upscale_factor)\n",
    "\n",
    "        deconv = tf.nn.conv2d_transpose(value=input,\n",
    "                                        filter=weights,\n",
    "                                        output_shape=deconv_shape,\n",
    "                                        strides=strides,\n",
    "                                        padding='SAME')\n",
    "    return deconv\n",
    "\n",
    "\n",
    "def get_bilinear_filter(filter_shape, upscale_factor):\n",
    "    # filter_shape is [width, height, num_in_channels, num_out_channels]\n",
    "    kernel_size = filter_shape[1]\n",
    "    ## Centre location of the filter for which value is calculated\n",
    "    if kernel_size % 2 == 1:\n",
    "        centre_location = upscale_factor - 1\n",
    "    else:\n",
    "        centre_location = upscale_factor - 0.5\n",
    "\n",
    "    bilinear = np.zeros([filter_shape[0], filter_shape[1]])\n",
    "    for x in range(filter_shape[0]):\n",
    "        for y in range(filter_shape[1]):\n",
    "            # Interpolation Calculation\n",
    "            value = (1 - abs((x - centre_location) / upscale_factor)) * (\n",
    "                        1 - abs((y - centre_location) / upscale_factor))\n",
    "            bilinear[x, y] = value\n",
    "    weights = np.zeros(filter_shape)\n",
    "    for i in range(filter_shape[2]):\n",
    "        weights[:, :, i, i] = bilinear\n",
    "    init = tf.constant_initializer(value=weights,\n",
    "                                   dtype=tf.float32)\n",
    "\n",
    "    bilinear_weights = tf.get_variable(name=\"decon_bilinear_filter\", initializer=init,\n",
    "                                       shape=weights.shape)\n",
    "    return bilinear_weights\n",
    "\n",
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "\n",
    "def create_biases(size):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_channels = 3\n",
    "initial_im_size= 768\n",
    "filter_size_conv1 =  3\n",
    "num_filters_conv1 = 64\n",
    "filter_size_conv2 = 3\n",
    "num_filters_conv2 = 64\n",
    "num_features = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1 = create_convolutional_layer(input=tf.cast(x,tf.float32),\n",
    "                                         num_input_channels=num_channels,\n",
    "                                         conv_filter_size=filter_size_conv1,\n",
    "                                         num_filters=num_filters_conv1,\n",
    "                                         maxpool=0,\n",
    "                                         name=\"conv_layer_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "layer_conv2 = create_convolutional_layer(input=layer_conv1,\n",
    "                                         num_input_channels=num_filters_conv1,\n",
    "                                         conv_filter_size=filter_size_conv2,\n",
    "                                         num_filters=num_filters_conv2,\n",
    "                                         maxpool=0,\n",
    "                                         name='conv_layer_2')\n",
    "\n",
    "pool = tf.nn.max_pool(value=layer_conv2,\n",
    "                      ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1],\n",
    "                      padding='SAME')\n",
    "\n",
    "feature_maps = create_deconvolutional_layer(input=pool,\n",
    "                                            num_filters=num_filters_conv2,\n",
    "                                            name='deconvolution',\n",
    "                                            upscale_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/margheritarosnati/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "time: 18.075649976730347\n"
     ]
    }
   ],
   "source": [
    "# eval \n",
    "np_feature_maps = tf_eval(feature_maps,timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 768, 768, 64), 0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_feature_maps.shape, np.sum(np.isnan(np_feature_maps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### region_proposal_network\n",
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_convolution(input,\n",
    "                       num_input_channels,\n",
    "                       conv_filter_size,\n",
    "                       num_filters,\n",
    "                       stride=1,\n",
    "                       data_format=\"NHWC\"):\n",
    "    '''\n",
    "    Simplified version of create_convolutional_layer that doesn't include max pooling or activation function\n",
    "    :param input: input tensor\n",
    "    :param num_input_channels: number of input channels\n",
    "    :param conv_filter_size: width and height of square conv filter\n",
    "    :param num_filters: number of filters to be applied\n",
    "    :param stride: scalar stride size for both width and height\n",
    "    :param data_format: see tensorflow documentation\n",
    "    :return:\n",
    "    '''\n",
    "    if data_format == \"NHWC\":\n",
    "        strides = [1, stride, stride, 1]\n",
    "    elif data_format == \"NCHW\":\n",
    "        strides = [1, 1, stride, stride]\n",
    "    ## We shall define the weights that will be trained using create_weights function.\n",
    "    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "    ## We create biases using the create_biases function. These are also trained.\n",
    "    biases = create_biases(num_filters)\n",
    "\n",
    "\n",
    "    ## Creating the convolutional layer\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=strides,\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "sliding_hidden_layer_size = 64\n",
    "n_proposal_boxes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#with tf.name_scope('sliding_window'):\n",
    "window_outputs = create_convolution(input=feature_maps,\n",
    "                                    num_input_channels=num_features,\n",
    "                                    conv_filter_size=window_size,\n",
    "                                    num_filters=sliding_hidden_layer_size,\n",
    "                                    stride=1,\n",
    "                                    data_format=\"NHWC\")\n",
    "\n",
    "#with tf.name_scope('classification_layer'):\n",
    "class_scores = create_convolution(input=window_outputs,\n",
    "                                       num_input_channels=sliding_hidden_layer_size,\n",
    "                                       conv_filter_size=1,\n",
    "                                       num_filters=n_proposal_boxes,\n",
    "                                       stride=1,\n",
    "                                       data_format=\"NHWC\")\n",
    "#with tf.name_scope('regression_layer'):\n",
    "# reg_outputs: [batch_size, 768, 768, 4*self.config.n_proposal_boxes]\n",
    "reg_outputs = create_convolution(input=window_outputs,\n",
    "                                     num_input_channels=sliding_hidden_layer_size,\n",
    "                                     conv_filter_size=1,\n",
    "                                     num_filters=4*n_proposal_boxes,\n",
    "                                     stride=1,\n",
    "                                     data_format=\"NHWC\")\n",
    "\n",
    "# self.reg_scores: [batch_size, 768, 768, self.config.n_proposal_boxes, 4]\n",
    "reg_scores = tf.reshape(tensor=reg_outputs,\n",
    "                             shape=[-1, 768, 768, n_proposal_boxes, 4],\n",
    "                             name='reshape_regression_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(2), Dimension(768), Dimension(768), Dimension(1), Dimension(4)]),\n",
       " TensorShape([Dimension(2), Dimension(768), Dimension(768), Dimension(1), Dimension(4)]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reg_gt.shape, reg_anchors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.002481698989868\n",
      "time: 26.203938961029053\n"
     ]
    }
   ],
   "source": [
    "# eval \n",
    "np_class_scores = tf_eval(class_scores, timed=1)\n",
    "np_reg_scores = tf_eval(reg_scores,timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 768, 768, 1) (2, 768, 768, 1, 4)\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(np_class_scores.shape, np_reg_scores.shape)\n",
    "print(np.sum(np.isnan(np_class_scores)), np.sum(np.isnan(np_reg_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_scores = tf.convert_to_tensor(np_class_scores, tf.float32)\n",
    "reg_scores = tf.convert_to_tensor(np_reg_scores, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU Mask Shape <unknown>\n"
     ]
    }
   ],
   "source": [
    "sigmoid_ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_class,\n",
    "                                                     logits=class_scores)\n",
    "# Remember that we only look at positive (> upper iou thresh) and negative (< iou thresh) boxes\n",
    "print('IOU Mask Shape', class_mask.shape)\n",
    "masked_signoid_ce = tf.multiply(class_mask, sigmoid_ce)\n",
    "\n",
    "classification_loss_per_sample = tf.reduce_sum(masked_signoid_ce, axis = [1,2,3])\n",
    "classification_loss = tf.reduce_mean(classification_loss_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.103011846542358\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "np_classification_loss = tf_eval(classification_loss, timed =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5542912"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_classification_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_adjusted_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_x = (x_predict - x_anchor)/ w_anchor\n",
    "epsilon = 0.001\n",
    "t_x = (reg_scores[:, :, :, :, 0] - reg_anchors[:, :, :, :, 0]) / (reg_anchors[:, :, :, :, 2] + epsilon)\n",
    "t_x_star = (y_reg_gt[:, :, :, :, 0] - reg_anchors[:, :, :, :, 0]) / (reg_anchors[:, :, :, :, 2] + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t_y = (y_predict - y_anchor)/ h_anchor\n",
    "t_y = (reg_scores[:, :, :, :, 1] - reg_anchors[:, :, :, :, 1]) / (reg_anchors[:, :, :, :, 3] + epsilon)\n",
    "t_y_star = (y_reg_gt[:, :, :, :, 1] - reg_anchors[:, :, :, :, 1]) / (reg_anchors[:, :, :, :, 3] + epsilon)\n",
    "# t_w = log(w_predict / w_anchor)\n",
    "t_w_star = tf.log(y_reg_gt[:, :, :, :, 2] / (reg_anchors[:, :, :, :, 2]+ epsilon))\n",
    "# t_w = tf.maximum(tf.log(self.reg_scores[:, :, :, :, 2] / reg_anchors[:, :, :, :, 2]),\n",
    "#                  tf.cast(tf.fill(dims=tf.shape(t_w_star), value=-100000), dtype=tf.float32))\n",
    "t_w = tf.log(reg_scores[:, :, :, :, 2] / (reg_anchors[:, :, :, :, 2] + epsilon))\n",
    "# tf.constant(-100000, shape=tf.shape(t_w_star)))\n",
    "# t_h = log(h_predict / h_anchor)\n",
    "t_h_star = tf.log(y_reg_gt[:, :, :, :, 3] / (reg_anchors[:, :, :, :, 3] + epsilon))\n",
    "# t_h = tf.maximum(tf.log(self.reg_scores[:, :, :, :, 3] / reg_anchors[:, :, :, :, 3]),\n",
    "#                  tf.cast(tf.fill(dims=tf.shape(t_w_star), value=-100000), dtype=tf.float32))\n",
    "t_h = tf.log(reg_scores[:, :, :, :, 3] / (reg_anchors[:, :, :, :, 3] + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.759867906570435\n"
     ]
    }
   ],
   "source": [
    "np_t_x = tf_eval(t_x,timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(np_t_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.208181858062744\n"
     ]
    }
   ],
   "source": [
    "np_t_w = tf_eval(t_w, timed =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105928"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(np_t_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_w = tf.maximum(tf.log(reg_scores[:, :, :, :, 2] / reg_anchors[:, :, :, :, 2]),\n",
    "                 tf.cast(tf.fill(dims=tf.shape(t_w_star), value=-100000), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.304682970046997\n"
     ]
    }
   ],
   "source": [
    "np_t_w = tf_eval(t_w, timed =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105928"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(np_t_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.869354009628296\n",
      "1105920\n"
     ]
    }
   ],
   "source": [
    "t_w = tf.log(reg_scores[:, :, :, :, 2]+ epsilon / (reg_anchors[:, :, :, :, 2] + epsilon))\n",
    "np_t_w = tf_eval(t_w, timed =1)\n",
    "print(np.sum(np.isnan(np_t_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = reg_scores[:, :, :, :, 2] / reg_anchors[:, :, :, :, 2]\n",
    "np_temp = tf_eval(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2, 768, 768, 1),\n",
       " TensorShape([Dimension(2), Dimension(768), Dimension(768), Dimension(1)]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sum(np.isnan(np_temp)))\n",
    "np_temp.shape,reg_scores[:, :, :, :, 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_w = tf.log(tf.maximum(reg_scores[:, :, :, :, 2],\n",
    "                        tf.cast(tf.fill(dims=tf.shape(reg_scores[:, :, :, :, 2]), value=epsilon), dtype=tf.float32))\n",
    "                        / (reg_anchors[:, :, :, :, 2] + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.8116090297698975\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "np_t_w = tf_eval(t_w, timed =1)\n",
    "print(np.sum(np.isnan(np_t_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t_y = (y_predict - y_anchor)/ h_anchor\n",
    "t_y = (reg_scores[:, :, :, :, 1] - reg_anchors[:, :, :, :, 1]) / (reg_anchors[:, :, :, :, 3] + epsilon)\n",
    "t_y_star = (y_reg_gt[:, :, :, :, 1] - reg_anchors[:, :, :, :, 1]) / (reg_anchors[:, :, :, :, 3] + epsilon)\n",
    "# t_w = log(w_predict / w_anchor)\n",
    "t_w_star = tf.log(y_reg_gt[:, :, :, :, 2] / (reg_anchors[:, :, :, :, 2]+ epsilon))\n",
    "# t_w = tf.maximum(tf.log(self.reg_scores[:, :, :, :, 2] / reg_anchors[:, :, :, :, 2]),\n",
    "#                  tf.cast(tf.fill(dims=tf.shape(t_w_star), value=-100000), dtype=tf.float32))\n",
    "reg_adj_1 = tf.maximum(reg_scores[:, :, :, :, 2],\n",
    "           tf.cast(tf.fill(dims=tf.shape(reg_scores[:, :, :, :, 2]), value=epsilon), dtype=tf.float32))\n",
    "\n",
    "t_w = tf.log(reg_adj_1 / (reg_anchors[:, :, :, :, 2] + epsilon))\n",
    "# tf.constant(-100000, shape=tf.shape(t_w_star)))\n",
    "# t_h = log(h_predict / h_anchor)\n",
    "t_h_star = tf.log(y_reg_gt[:, py:, :, :, 3] / (reg_anchors[:, :, :, :, 3] + epsilon))\n",
    "# t_h = tf.maximum(tf.log(self.reg_scores[:, :, :, :, 3] / reg_anchors[:, :, :, :, 3]),\n",
    "#                  tf.cast(tf.fill(dims=tf.shape(t_w_star), value=-100000), dtype=tf.float32))\n",
    "reg_adj_2 = tf.maximum(reg_scores[:, :, :, :, 3],\n",
    "           tf.cast(tf.fill(dims=tf.shape(reg_scores[:, :, :, :, 3]), value=epsilon), dtype=tf.float32))\n",
    "\n",
    "t_h = tf.log(reg_adj_2 / (reg_anchors[:, :, :, :, 3] + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_reg_loss_pred = tf.stack([t_x, t_y, t_w, t_h], axis=4)\n",
    "y_reg_loss_gt = tf.stack([t_x_star, t_y_star, t_w_star, t_h_star], axis=4)\n",
    "\n",
    "\n",
    "regression_loss_per_pixel = tf.losses.mean_squared_error(labels=y_reg_loss_gt,\n",
    "                                                     predictions=y_reg_loss_pred,\n",
    "                                                     reduction=tf.losses.Reduction.NONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.68030881881714\n"
     ]
    }
   ],
   "source": [
    "np_regression_loss_per_pixel = tf_eval(regression_loss_per_pixel, timed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(np_regression_loss_per_pixel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
